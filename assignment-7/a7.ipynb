{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prerequesites\n",
    "\n",
    "Run ```conda install asyncio asynchttp nest_asyncio pandas gzip``` before running the code\n",
    "or you can run the below command to install the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %conda install asyncio asynchttp nest_asyncio pandas gzip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1a [CSCI 490] Download & Extract Files (20 pts)\n",
    "\n",
    "import requests\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "decades_urls = ['http://faculty.cs.niu.edu/~dakoop/cs503-2022sp/a7/unemp-' +\n",
    "                str(i) + '.zip' for i in range(1970, 2021, 10)]\n",
    "\n",
    "def download_files_and_extract(url, response):\n",
    "    file_name = url.split('/')[-1]\n",
    "    current_dir_path = os.getcwd() + '/'\n",
    "    zip_file_path = current_dir_path + file_name\n",
    "\n",
    "    if not os.path.exists(zip_file_path):\n",
    "        with open(zip_file_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "\n",
    "    unzip_file_name = file_name.split('.')[0]\n",
    "    unzip_file_path = current_dir_path + unzip_file_name\n",
    "    if not os.path.exists(unzip_file_path):\n",
    "        with zipfile.ZipFile(zip_file_path,\"r\") as zf:\n",
    "            zf.extractall(current_dir_path)\n",
    "    if os.path.exists(zip_file_path):\n",
    "        os.remove(zip_file_path)\n",
    "\n",
    "for url in decades_urls:\n",
    "    response = requests.get(url)\n",
    "    download_files_and_extract(url, response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1b [CSCI 503] Download & Extract Files (30 pts)\n",
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def extract_files_async(session, url):\n",
    "    file_name = url.split('/')[-1]\n",
    "    current_dir_path = os.getcwd() + '/'\n",
    "    zip_file_path = current_dir_path + file_name\n",
    "\n",
    "    if not os.path.exists(zip_file_path):\n",
    "        async with aiofiles.open(zip_file_path, mode='w') as f:\n",
    "            await f.write()\n",
    "\n",
    "    unzip_file_name = file_name.split('.')[0]\n",
    "    unzip_file_path = current_dir_path + unzip_file_name\n",
    "    if not os.path.exists(unzip_file_path):\n",
    "        with zipfile.ZipFile(zip_file_path,\"r\") as zf:\n",
    "            zf.extractall(current_dir_path)\n",
    "\n",
    "    if os.path.exists(zip_file_path):\n",
    "        os.remove(zip_file_path)\n",
    "\n",
    "async def dowload_file_async(session, url):\n",
    "    async with session.get(url) as response:\n",
    "        await extract_files_async(url, response)\n",
    "        \n",
    "async def download_all_files_async(decades_urls):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        for url in decades_urls:\n",
    "            task = asyncio.ensure_future(dowload_file_async(session, url))\n",
    "            tasks.append(task)\n",
    "        await asyncio.gather(*tasks, return_exceptions=True)\n",
    "\n",
    "asyncio.get_event_loop().run_until_complete(download_all_files_async(decades_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/workspace/CSCI_Assignments/assignment-7/unemp-1970/unemp.csv', '/workspace/CSCI_Assignments/assignment-7/unemp-1980/unemp.csv', '/workspace/CSCI_Assignments/assignment-7/unemp-1990/employment.csv', '/workspace/CSCI_Assignments/assignment-7/unemp-2000/unemployment.csv', '/workspace/CSCI_Assignments/assignment-7/unemp-2010/employment.csv', '/workspace/CSCI_Assignments/assignment-7/unemp-2020/unemp.csv']\n"
     ]
    }
   ],
   "source": [
    "# 2 Find Matching Files (10 pts)\n",
    "import glob\n",
    "\n",
    "matched_files = [os.getcwd() + '/' + i for i in glob.glob(\"**/*.csv\", recursive = True)]\n",
    "print(matched_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Use Threads to Process Files (30 pts)\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import pandas as pd\n",
    "import gzip\n",
    "\n",
    "def process_data(data_file):\n",
    "    df = pd.read_csv(data_file)\n",
    "    df['COUNTY'] = df['COUNTY'].str.upper()\n",
    "    df = df[df['COUNTY'].isin(counties_with_suffix)]\n",
    "    df['RATE'] = df['UNEMPLOYED_NUMBER']/df['LABOR_FORCE']\n",
    "    return df\n",
    "\n",
    "counties_no_suffix = [\"DEKALB\", \"KANE\", \"BOONE\", \"MCHENRY\", \"WINNEBAGO\", \"OGLE\", \"LEE\",\"KENDALL\"]\n",
    "counties_with_suffix = list(map(lambda x: x + ' COUNTY', counties_no_suffix))\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=13) as e:\n",
    "    result = pd.concat(list(e.map(process_data, matched_files)))\n",
    "    for i in counties_no_suffix:\n",
    "        county_df = result[result['COUNTY'] == str(i) + ' COUNTY']\n",
    "        county_df.to_csv(str(i) + '.csv.gz', index=False, compression=\"gzip\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOONE 0.08099938784155404\n",
      "DEKALB 0.05766694572727062\n",
      "KANE 0.06465744592318971\n",
      "KENDALL 0.05521362047852945\n",
      "LEE 0.06341724493660843\n",
      "MCHENRY 0.05963539940389765\n",
      "OGLE 0.06660581534993118\n",
      "WINNEBAGO 0.07757288231143361\n"
     ]
    }
   ],
   "source": [
    "counties_no_suffix = ['DEKALB', 'KANE', 'BOONE', 'MCHENRY', 'WINNEBAGO', 'OGLE', 'LEE', 'KENDALL'] \n",
    "for c in sorted(counties_no_suffix):\n",
    "    cdf = pd.read_csv(f'{c}.csv.gz')\n",
    "    print(c, cdf.RATE.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional Delete files and folders\n",
    "# If not needed comment the code and run all the cells again.\n",
    "\n",
    "import shutil\n",
    "\n",
    "for url in decades_urls:\n",
    "    decades_dirs = os.getcwd() + '/' + url.split('/')[-1].split('.')[0]\n",
    "    if os.path.exists(decades_dirs):\n",
    "        shutil.rmtree(decades_dirs)\n",
    "\n",
    "for i in counties_no_suffix:\n",
    "    fname = os.getcwd() + '/' + str(i) + '.csv.gz'\n",
    "    if os.path.exists(fname):\n",
    "        os.remove(fname)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('3.8.12')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
